{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb500e96-6b1e-4c07-a475-35f45a1ece2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Session1...\n",
      "Error reading C:\\Users\\PC\\Documents\\Research Work\\Data\\Output_segF\\Output_segF\\Sessions\\Session1\\Classes_session_1.xlsx: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.\n",
      "Determined input shape: (62, 64, 800, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to read a single .mat file\n",
    "def read_mat_file(file_path):\n",
    "    try:\n",
    "        mat_data = scipy.io.loadmat(file_path)\n",
    "        eeg_data = mat_data['paddedData']\n",
    "        return eeg_data\n",
    "    except KeyError:\n",
    "        print(f\"Key 'paddedData' not found in {file_path}\")\n",
    "        return None\n",
    "    except OSError as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to read labels from xlsx\n",
    "def read_labels(xlsx_path):\n",
    "    try:\n",
    "        labels_df = pd.read_excel(xlsx_path)\n",
    "        labels = {row['Name']: row['classes'] for _, row in labels_df.iterrows()}\n",
    "        return labels\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {xlsx_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Generator function to load data in batches\n",
    "def data_generator(folder_path, labels, batch_size, num_classes):\n",
    "    file_names = sorted(os.listdir(folder_path))\n",
    "    total_files = len(file_names)\n",
    "    while True:\n",
    "        for start in range(0, total_files, batch_size):\n",
    "            end = min(start + batch_size, total_files)\n",
    "            batch_data = []\n",
    "            batch_labels = []\n",
    "            for file_name in file_names[start:end]:\n",
    "                if file_name.endswith('.mat'):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    eeg_data = read_mat_file(file_path)\n",
    "                    if eeg_data is not None and file_name in labels:\n",
    "                        label = labels[file_name]\n",
    "                        batch_data.append(eeg_data)\n",
    "                        batch_labels.append(label)\n",
    "            if batch_data and batch_labels:\n",
    "                batch_data = np.array(batch_data)\n",
    "                batch_labels = np.array(batch_labels)\n",
    "                batch_labels = to_categorical(batch_labels, num_classes)\n",
    "                batch_data = batch_data[..., np.newaxis]\n",
    "                yield batch_data, batch_labels\n",
    "\n",
    "# Function to handle sessions\n",
    "def handle_session(folder_path, xlsx_path, batch_size, num_classes):\n",
    "    labels = read_labels(xlsx_path)\n",
    "    sample_file = os.path.join(folder_path, sorted(os.listdir(folder_path))[0])\n",
    "    sample_data = read_mat_file(sample_file)\n",
    "    if sample_data is not None:\n",
    "        input_shape = sample_data.shape + (1,)\n",
    "        print(\"Determined input shape:\", input_shape)\n",
    "    else:\n",
    "        print(\"Unable to determine input shape. Please check the data.\")\n",
    "        raise ValueError(\"Unable to determine input shape.\")\n",
    "    data_gen = data_generator(folder_path, labels, batch_size, num_classes)\n",
    "    num_files = len(os.listdir(folder_path))\n",
    "    steps_per_epoch = num_files // batch_size\n",
    "    return data_gen, input_shape, steps_per_epoch\n",
    "\n",
    "session_paths = {\n",
    "    'Session1': (r'C:\\Users\\PC\\Documents\\Research Work\\Data\\Output_segF\\Output_segF\\Sessions\\Session1\\Equilize', r'C:\\Users\\PC\\Documents\\Research Work\\Data\\Output_segF\\Output_segF\\Sessions\\Session1\\Classes_session_1.xlsx'),\n",
    "    'Session2': (r'C:\\Users\\PC\\Documents\\Research Work\\Data\\Output_segF\\Output_segF\\Sessions\\Session2\\Equilizer', r'C:\\Users\\PC\\Documents\\Research Work\\Data\\Output_segF\\Output_segF\\Sessions\\Session2\\Classes_session_2.xlsx'),\n",
    "    'Session3': (r'C:\\Users\\PC\\Documents\\Research Work\\Data\\Output_segF\\Output_segF\\Sessions\\Session3\\Equilizer', r'C:\\Users\\PC\\Documents\\Research Work\\Data\\Output_segF\\Output_segF\\Sessions\\Session3\\Classes_session_3.xlsx')\n",
    "}\n",
    "\n",
    "batch_size = 32  # Adjust batch size as needed\n",
    "num_classes = 4  # Set the number of classes\n",
    "\n",
    "# Process each session\n",
    "for session_name, (folder_path, xlsx_path) in session_paths.items():\n",
    "    print(f\"Processing {session_name}...\")\n",
    "    data_gen, input_shape, steps_per_epoch = handle_session(folder_path, xlsx_path, batch_size, num_classes)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(data_gen, steps_per_epoch=steps_per_epoch, epochs=10)\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title(f'Model accuracy for {session_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title(f'Model loss for {session_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Completed processing {session_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e3394-a144-4ec1-9732-5c51e3641a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "tf-gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
